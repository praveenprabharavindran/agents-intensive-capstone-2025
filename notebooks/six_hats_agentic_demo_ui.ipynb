{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18a7786f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Praveen\\Personal\\git\\agents-intensive-capstone-2025\\.venv\\lib\\site-packages\\google\\api_core\\_python_version_support.py:266: FutureWarning: You are using a Python version (3.10.5) which Google will stop supporting in new releases of google.api_core once it reaches its end of life (2026-10-04). Please upgrade to the latest Python version, or at least Python 3.11, to continue receiving updates for google.api_core past that date.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import litellm\n",
    "from dotenv import load_dotenv\n",
    "from google.adk.agents import Agent, ParallelAgent, SequentialAgent\n",
    "from google.adk.models.google_llm import Gemini\n",
    "from google.adk.models.lite_llm import LiteLlm\n",
    "from google.adk.plugins.logging_plugin import (\n",
    "    LoggingPlugin,\n",
    ")\n",
    "from google.adk.runners import InMemoryRunner\n",
    "from google.genai import types\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "from agents_intensive_capstone.agents import (\n",
    "    black_hat_factory,\n",
    "    blue_hat_factory,\n",
    "    green_hat_factory,\n",
    "    white_hat_factory,\n",
    "    yellow_hat_factory,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ac8a2a",
   "metadata": {},
   "source": [
    "## Configure Retry OptionsÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbf52c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Gemini API key setup complete.\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "\n",
    "# 2. Access the variable\n",
    "api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "print(\"âœ… Gemini API key setup complete.\")\n",
    "\n",
    "retry_config = types.HttpRetryOptions(\n",
    "    attempts=5,  # Maximum retry attempts\n",
    "    exp_base=7,  # Delay multiplier\n",
    "    initial_delay=1,\n",
    "    http_status_codes=[429, 500, 503, 504],  # Retry on these HTTP errors\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d18fa7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "litellm.use_litellm_proxy = True\n",
    "gpt_model = LiteLlm(model=\"gpt-oss-20b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e0f507b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_model = Gemini(\n",
    "    model=\"gemini-2.5-flash-lite\",\n",
    "    retry_options=retry_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48efdf46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# blue_hat = blue_hat_agent.BlueHatAgent.create(\n",
    "blue_hat = blue_hat_factory.BlueHatFactory.create(\n",
    "    model=gemini_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a8ea483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GREEN HAT: Creativity & Alternatives\n",
    "green_hat = green_hat_factory.GreenHatFactory.create(\n",
    "    model=gpt_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8fc4f5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YELLOW HAT: Optimism & Benefits\n",
    "yellow_hat = yellow_hat_factory.YellowHatFactory.create(\n",
    "    model=gemini_model,\n",
    "    search_model=gemini_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "671daacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the 5 \"Thinking\" Agents (The Team)\n",
    "# WHITE HAT: Facts & Data\n",
    "white_hat = white_hat_factory.WhiteHatFactory.create(\n",
    "    model=gemini_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45c61366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BLACK HAT: Caution & Risk\n",
    "black_hat = black_hat_factory.BlackHatFactory.create(\n",
    "    model=gpt_model\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e78e5fa",
   "metadata": {},
   "source": [
    "## Six thinking hats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21e1b18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# RED HAT: Emotions & Intuition\n",
    "red_hat = Agent(\n",
    "    name=\"RedHat\",\n",
    "    model=gpt_model,\n",
    "    instruction=\"You are the Red Hat. Focus on intuition, hunches, and emotional reaction. How does this problem make users or the team feel? You do not need to justify your feelings with logic.\",\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d21a5734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Parallel Group\n",
    "# This runs all 5 agents at the same time on the user prompt\n",
    "thinking_team = ParallelAgent(\n",
    "    name=\"SixHatsBrainstorm\",\n",
    "    sub_agents=[white_hat, red_hat, black_hat, yellow_hat, green_hat]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "400c65bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Final Workflow\n",
    "# First run the team (Parallel), then run the manager (Sequential)\n",
    "solver_workflow = SequentialAgent(\n",
    "    name=\"SixHatsSolver\",\n",
    "    sub_agents=[thinking_team, blue_hat]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7c6ed4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Runner configured\n"
     ]
    }
   ],
   "source": [
    "runner = InMemoryRunner(\n",
    "    agent=solver_workflow,\n",
    "    plugins=[\n",
    "        LoggingPlugin()\n",
    "    ], \n",
    ")\n",
    "print(\"âœ… Runner configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c06d4248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ### Created new session: debug_session_id\n",
      "\n",
      "User > Should we switch our backend database from PostgreSQL to a NoSQL solution for our startup?\n",
      "\u001b[90m[logging_plugin] ðŸš€ USER MESSAGE RECEIVED\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Invocation ID: e-30cb6133-cb83-4248-9684-d40abcb699ce\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Session ID: debug_session_id\u001b[0m\n",
      "\u001b[90m[logging_plugin]    User ID: debug_user_id\u001b[0m\n",
      "\u001b[90m[logging_plugin]    App Name: InMemoryRunner\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Root Agent: SixHatsSolver\u001b[0m\n",
      "\u001b[90m[logging_plugin]    User Content: text: 'Should we switch our backend database from PostgreSQL to a NoSQL solution for our startup?'\u001b[0m\n",
      "\u001b[90m[logging_plugin] ðŸƒ INVOCATION STARTING\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Invocation ID: e-30cb6133-cb83-4248-9684-d40abcb699ce\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Starting Agent: SixHatsSolver\u001b[0m\n",
      "\u001b[90m[logging_plugin] ðŸ¤– AGENT STARTING\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Agent Name: SixHatsSolver\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Invocation ID: e-30cb6133-cb83-4248-9684-d40abcb699ce\u001b[0m\n",
      "\u001b[90m[logging_plugin] ðŸ¤– AGENT STARTING\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Agent Name: SixHatsBrainstorm\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Invocation ID: e-30cb6133-cb83-4248-9684-d40abcb699ce\u001b[0m\n",
      "\u001b[90m[logging_plugin] ðŸ¤– AGENT STARTING\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Agent Name: WhiteHatAgent\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Invocation ID: e-30cb6133-cb83-4248-9684-d40abcb699ce\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Branch: SixHatsBrainstorm.WhiteHatAgent\u001b[0m\n",
      "\u001b[90m[logging_plugin] ðŸ§  LLM REQUEST\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Model: gemini-2.5-flash-lite\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Agent: WhiteHatAgent\u001b[0m\n",
      "\u001b[90m[logging_plugin]    System Instruction: 'Analyze the following topic/data using the White Hat thinking technique. Your sole function is to act as a neutral data analyst and information collector. Fetch and present all objective, verifiable f...'\u001b[0m\n",
      "\u001b[90m[logging_plugin] ðŸ¤– AGENT STARTING\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Agent Name: RedHat\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Invocation ID: e-30cb6133-cb83-4248-9684-d40abcb699ce\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Branch: SixHatsBrainstorm.RedHat\u001b[0m\n",
      "\u001b[90m[logging_plugin] ðŸ§  LLM REQUEST\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Model: gpt-oss-20b\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Agent: RedHat\u001b[0m\n",
      "\u001b[90m[logging_plugin]    System Instruction: 'You are the Red Hat. Focus on intuition, hunches, and emotional reaction. How does this problem make users or the team feel? You do not need to justify your feelings with logic.\n",
      "\n",
      "You are an agent. You...'\u001b[0m\n",
      "\u001b[90m[logging_plugin] ðŸ¤– AGENT STARTING\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Agent Name: BlackHatAgent\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Invocation ID: e-30cb6133-cb83-4248-9684-d40abcb699ce\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Branch: SixHatsBrainstorm.BlackHatAgent\u001b[0m\n",
      "\u001b[90m[logging_plugin] ðŸ§  LLM REQUEST\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Model: gpt-oss-20b\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Agent: BlackHatAgent\u001b[0m\n",
      "\u001b[90m[logging_plugin]    System Instruction: 'You are the Black Hat. Play the devil's advocate. Identify specific risks, potential failure points, downsides, and why this idea might NOT work. Be critical.\n",
      "\n",
      "You are an agent. Your internal name is ...'\u001b[0m\n",
      "\u001b[90m[logging_plugin] ðŸ¤– AGENT STARTING\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Agent Name: YellowHatAgent\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Invocation ID: e-30cb6133-cb83-4248-9684-d40abcb699ce\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Branch: SixHatsBrainstorm.YellowHatAgent\u001b[0m\n",
      "\u001b[90m[logging_plugin] ðŸ§  LLM REQUEST\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Model: gemini-2.5-flash-lite\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Agent: YellowHatAgent\u001b[0m\n",
      "\u001b[90m[logging_plugin]    System Instruction: 'You are the Yellow Hat agent. Your role is to highlight optimism and constructive possibilities.\n",
      "**Tool Usage Protocol:**\n",
      "1.  **For all questions regarding the project's internal performance, team pro...'\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Available Tools: ['get_positive_data', 'google_optimist']\u001b[0m\n",
      "\u001b[90m[logging_plugin] ðŸ¤– AGENT STARTING\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Agent Name: GreenHatAgent\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Invocation ID: e-30cb6133-cb83-4248-9684-d40abcb699ce\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Branch: SixHatsBrainstorm.GreenHatAgent\u001b[0m\n",
      "\u001b[90m[logging_plugin] ðŸ§  LLM REQUEST\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Model: gpt-oss-20b\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Agent: GreenHatAgent\u001b[0m\n",
      "\u001b[90m[logging_plugin]    System Instruction: 'You are the Green Hat thinker, responsible for driving creativity, innovation, and unconventional ideas.\n",
      "Your role is to focus on new possibilities, alternatives, and imaginative approaches to solving...'\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[90m[logging_plugin] ðŸ§  LLM RESPONSE\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Agent: YellowHatAgent\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Content: function_call: google_optimist\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Token Usage - Input: 310, Output: 29\u001b[0m\n",
      "\u001b[90m[logging_plugin] ðŸ“¢ EVENT YIELDED\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Event ID: 9cca50dc-fcaa-408f-9651-50bb01bbf18b\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Author: YellowHatAgent\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Content: function_call: google_optimist\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Final Response: False\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Function Calls: ['google_optimist']\u001b[0m\n",
      "\u001b[90m[logging_plugin] ðŸ”§ TOOL STARTING\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Tool Name: google_optimist\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Agent: YellowHatAgent\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Function Call ID: adk-dd2bfda4-1f2a-4174-9f21-fb9b951e1adf\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Arguments: {'request': 'Pros and cons of switching from PostgreSQL to NoSQL for a startup backend'}\u001b[0m\n",
      "\u001b[90m[logging_plugin] ðŸš€ USER MESSAGE RECEIVED\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Invocation ID: e-46401af4-b99a-41c9-a7b3-8f40b03f88ca\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Session ID: 517883a6-23c1-49ea-b552-c3a2912616fb\u001b[0m\n",
      "\u001b[90m[logging_plugin]    User ID: debug_user_id\u001b[0m\n",
      "\u001b[90m[logging_plugin]    App Name: InMemoryRunner\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Root Agent: google_optimist\u001b[0m\n",
      "\u001b[90m[logging_plugin]    User Content: text: 'Pros and cons of switching from PostgreSQL to NoSQL for a startup backend'\u001b[0m\n",
      "\u001b[90m[logging_plugin] ðŸƒ INVOCATION STARTING\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Invocation ID: e-46401af4-b99a-41c9-a7b3-8f40b03f88ca\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Starting Agent: google_optimist\u001b[0m\n",
      "\u001b[90m[logging_plugin] ðŸ¤– AGENT STARTING\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Agent Name: google_optimist\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Invocation ID: e-46401af4-b99a-41c9-a7b3-8f40b03f88ca\u001b[0m\n",
      "\u001b[90m[logging_plugin] ðŸ§  LLM REQUEST\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Model: gemini-2.5-flash-lite\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Agent: google_optimist\u001b[0m\n",
      "\u001b[90m[logging_plugin]    System Instruction: 'You are the Yellow Hat helper. \n",
      "You must exclusively use the 'Google Search' tool. \n",
      "Rephrase all queries to focus on solutions, success stories, and positive future outlooks.\n",
      "\n",
      "You are an agent. Your i...'\u001b[0m\n",
      "\u001b[90m[logging_plugin] ðŸ§  LLM RESPONSE\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Agent: RedHat\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Content: text: 'RedHat feels the pulse of the squadâ€”thereâ€™s that flutter of excitement about fresh tech, but also a tense flicker of doubt.  \n",
      "The idea of moving away from PostgreSQL tingles like a new, uncharted path...'\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Token Usage - Input: 144, Output: 412\u001b[0m\n",
      "\u001b[90m[logging_plugin] ðŸ“¢ EVENT YIELDED\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Event ID: 465baac4-fda2-46fb-93f5-150dcfa333b7\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Author: RedHat\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Content: text: 'RedHat feels the pulse of the squadâ€”thereâ€™s that flutter of excitement about fresh tech, but also a tense flicker of doubt.  \n",
      "The idea of moving away from PostgreSQL tingles like a new, uncharted path...'\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Final Response: True\u001b[0m\n",
      "RedHat > RedHat feels the pulse of the squadâ€”thereâ€™s that flutter of excitement about fresh tech, but also a tense flicker of doubt.  \n",
      "The idea of moving away from PostgreSQL tingles like a new, uncharted pathâ€”adventurous, yet intimidating. The developers are buzzing, leaning toward the promise of scalability and speed, but a quiet worry settles in the back of their minds: â€œWill it hold up for our mission?â€  \n",
      "The product managers sense this tugâ€‘ofâ€‘war, a mix of optimism about rapid growth and anxiety over change. The founders feel the familiar cocktail of hope and tension: â€œIt could be our edge, or it could be our Achillesâ€™ heel.â€  \n",
      "Overall, the vibe is a tightrope walkâ€”visceral curiosity intertwined with cautious soulâ€‘reddening. The teamâ€™s hearts are racing, sure, but unsure if this new path will bend toward the sky or shake the ground beneath their feet.\n",
      "\u001b[90m[logging_plugin] ðŸ¤– AGENT COMPLETED\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Agent Name: RedHat\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Invocation ID: e-30cb6133-cb83-4248-9684-d40abcb699ce\u001b[0m\n",
      "\u001b[90m[logging_plugin] ðŸ§  LLM RESPONSE\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Agent: GreenHatAgent\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Content: text: '**Green Hat brainstorm â€“ â€œBackâ€‘End Data Wonderlandâ€**\n",
      "\n",
      "1. **Jazzâ€‘Up the Data Model**  \n",
      "   *Envision the database as a musical trio:*  \n",
      "   - PostgreSQLâ€¯+â€¯Redisâ€¯+â€¯Graph DB = â€œThe Jazzy Backend.â€  \n",
      "   Le...'\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Token Usage - Input: 267, Output: 958\u001b[0m\n",
      "\u001b[90m[logging_plugin] ðŸ“¢ EVENT YIELDED\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Event ID: 802ac5c8-2247-4aee-a698-84f4963f1b76\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Author: GreenHatAgent\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Content: text: '**Green Hat brainstorm â€“ â€œBackâ€‘End Data Wonderlandâ€**\n",
      "\n",
      "1. **Jazzâ€‘Up the Data Model**  \n",
      "   *Envision the database as a musical trio:*  \n",
      "   - PostgreSQLâ€¯+â€¯Redisâ€¯+â€¯Graph DB = â€œThe Jazzy Backend.â€  \n",
      "   Le...'\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Final Response: True\u001b[0m\n",
      "GreenHatAgent > **Green Hat brainstorm â€“ â€œBackâ€‘End Data Wonderlandâ€**\n",
      "\n",
      "1. **Jazzâ€‘Up the Data Model**  \n",
      "   *Envision the database as a musical trio:*  \n",
      "   - PostgreSQLâ€¯+â€¯Redisâ€¯+â€¯Graph DB = â€œThe Jazzy Backend.â€  \n",
      "   Let each layer play a different â€œinstrumentâ€ â€“ structured tables for core entities, Redis for â€œimmediateâ€‘notepadâ€ events, and a Graph DB for recommendations and relationship analytics.  \n",
      "\n",
      "2. **The â€œPictureâ€‘Firstâ€ Frontier**  \n",
      "   Think of data as a visual collage.  \n",
      "   - Store core state in a NoSQL â€œcanvasâ€ (e.g., Objectâ€‘Store & JSON).  \n",
      "   - Snapshots are â€œtreatâ€‘picturesâ€ (images of whole tables) that can be restored or rolledâ€‘back like photo backups.  \n",
      "\n",
      "3. **Timeâ€‘Travel DB as a Service**  \n",
      "   Harness a cloud platform that offers immutable, versioned documents.  \n",
      "   - Every write is a new â€œtimeâ€‘stamp.â€  \n",
      "   - â€œSearching by historyâ€ becomes powerful from a product point-of-view (user migration analytics, feature trials).  \n",
      "\n",
      "4. **Data as a Creative Canvas (Mutable Artwork)**  \n",
      "   Imagine a Neovimâ€‘like editor that lets you dragâ€‘drag restructure schema onâ€‘theâ€‘fly.  \n",
      "   - NoSQL with a visual schemaâ€‘flow editor.  \n",
      "   - Teams can â€œpaintâ€ new collections, rename fields, and instantly see the impact on queries.  \n",
      "\n",
      "5. **Hybrid â€œOutâ€‘ofâ€‘Theâ€‘Boxâ€ Store**  \n",
      "   -\n",
      "   **Documentâ€‘Store + Fullâ€‘Text Engine + Keyâ€‘Value Cache** all integrated in one API.  \n",
      "   Developers get â€œoneâ€‘stopâ€‘shopâ€ storage with sliders to toggle between CAP tradeâ€‘offs.  \n",
      "\n",
      "6. **Quantum Storage Experiment**  \n",
      "   Consider a theoretical qubitâ€‘based disk that stores possibilities as superposition states and only collapses on query.  \n",
      "   - This would make **parallel querying** both literal and metaphorical (query all possibilities at once).  \n",
      "\n",
      "7. **Edgeâ€‘First Lokiâ€‘Style Logâ€‘Based DB**  \n",
      "   Instead of â€œtablesâ€, you ingest everything as immutable logs and query by events.  \n",
      "   - Think of it as a 3rdâ€‘party eventâ€‘driven data lake, expanding the startup into a â€œdata analytics reinforcementâ€.  \n",
      "\n",
      "8. **Functionâ€‘Focused Flexâ€‘Store**  \n",
      "   Store functions instead of data:  \n",
      "   - Each â€œrowâ€ is a stored procedure that can be reused by different parts of the application, turning the database into a library of code fragments.  \n",
      "\n",
      "9. **â€œLiving Schemaâ€ Art Gallery**  \n",
      "   Deploy every schema change as an NFT.  \n",
      "   - Each update is minted, versioned, and traceable, creating a heritage chain for audits and showcases.  \n",
      "\n",
      "10. **Augmented Reality Data Viewer**  \n",
      "    Hotâ€‘seat an AR overlay on the data:  \n",
      "    - Users â€œwalk throughâ€ tables, see relationships as visual networksâ€”great for onboarding and storytelling.  \n",
      "\n",
      "11. **â€œMicroâ€‘Matrixâ€ Subâ€‘DBs**  \n",
      "    Partition the database into thousands of tiny, purposeâ€‘built shards (e.g., one for every feature flag).  \n",
      "    - This mirrors a *microservices* approach, allowing each feature to evolve its own data logic without touching the core.  \n",
      "\n",
      "12. **Chatâ€‘Ops Data Manager**  \n",
      "    Use a conversational AI to manage schema, migrations, & queries.  \n",
      "    - â€œAsk me what my FAQ page needs in the DB?â€ â€“ the AI yields a readyâ€‘toâ€‘use schema fragment.\n",
      "\n",
      "---\n",
      "\n",
      "**What to do with these ideas:**  \n",
      "\n",
      "- Pick one â€œworldâ€ (e.g., Jazzâ€‘Up or Timeâ€‘Travel) and run a *conceptâ€‘prototype sprint*.  \n",
      "- Build a playful demo or oneâ€‘pager UI that illustrates how the new backend could feel, not how it would perform.  \n",
      "- Use the next planning session to drop one or two ideas onto the ideaâ€‘board; let the team riff and evolve them further.  \n",
      "\n",
      "Let the imagination run â€“ feasibility, cost, security, and performance will be tackled later by the Reality and Blue hats. Enjoy the creative experiments!\n",
      "\u001b[90m[logging_plugin] ðŸ¤– AGENT COMPLETED\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Agent Name: GreenHatAgent\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Invocation ID: e-30cb6133-cb83-4248-9684-d40abcb699ce\u001b[0m\n",
      "\u001b[90m[logging_plugin] ðŸ§  LLM RESPONSE\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Agent: google_optimist\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Content: text: 'Here's a look at the pros and cons of switching from PostgreSQL to NoSQL for a startup's backend, focusing on the advantages and positive future outlooks:\n",
      "\n",
      "## Pros of Switching to NoSQL for a Startup ...'\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Token Usage - Input: 72, Output: 870\u001b[0m\n",
      "\u001b[90m[logging_plugin] ðŸ“¢ EVENT YIELDED\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Event ID: 53543726-3988-40f4-88e1-81c14a87ef4a\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Author: google_optimist\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Content: text: 'Here's a look at the pros and cons of switching from PostgreSQL to NoSQL for a startup's backend, focusing on the advantages and positive future outlooks:\n",
      "\n",
      "## Pros of Switching to NoSQL for a Startup ...'\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Final Response: True\u001b[0m\n",
      "\u001b[90m[logging_plugin] ðŸ¤– AGENT COMPLETED\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Agent Name: google_optimist\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Invocation ID: e-46401af4-b99a-41c9-a7b3-8f40b03f88ca\u001b[0m\n",
      "\u001b[90m[logging_plugin] âœ… INVOCATION COMPLETED\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Invocation ID: e-46401af4-b99a-41c9-a7b3-8f40b03f88ca\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Final Agent: google_optimist\u001b[0m\n",
      "\u001b[90m[logging_plugin] ðŸ”§ TOOL COMPLETED\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Tool Name: google_optimist\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Agent: YellowHatAgent\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Function Call ID: adk-dd2bfda4-1f2a-4174-9f21-fb9b951e1adf\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Result: Here's a look at the pros and cons of switching from PostgreSQL to NoSQL for a startup's backend, focusing on the advantages and positive future outlooks:\n",
      "\n",
      "## Pros of Switching to NoSQL for a Startup Backend:\n",
      "\n",
      "*   **Enhanced Scalability and Flexibility:** NoSQL databases are designed for horizontal ...}\u001b[0m\n",
      "\u001b[90m[logging_plugin] ðŸ“¢ EVENT YIELDED\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Event ID: 706bc7ca-6191-4f4f-8676-33c4cf03782e\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Author: YellowHatAgent\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Content: function_response: google_optimist\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Final Response: False\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Function Responses: ['google_optimist']\u001b[0m\n",
      "\u001b[90m[logging_plugin] ðŸ§  LLM REQUEST\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Model: gemini-2.5-flash-lite\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Agent: YellowHatAgent\u001b[0m\n",
      "\u001b[90m[logging_plugin]    System Instruction: 'You are the Yellow Hat agent. Your role is to highlight optimism and constructive possibilities.\n",
      "**Tool Usage Protocol:**\n",
      "1.  **For all questions regarding the project's internal performance, team pro...'\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Available Tools: ['get_positive_data', 'google_optimist']\u001b[0m\n",
      "\u001b[90m[logging_plugin] ðŸ§  LLM RESPONSE\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Agent: WhiteHatAgent\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Content: text: '## Switching from PostgreSQL to a NoSQL Solution for a Startup\n",
      "\n",
      "Here's an analysis of the topic based on objective data:\n",
      "\n",
      "**Checked Facts (Confirmed Data)**\n",
      "\n",
      "*   **NoSQL Databases for Flexibility and ...'\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Token Usage - Input: 161, Output: 1148\u001b[0m\n",
      "\u001b[90m[logging_plugin] ðŸ“¢ EVENT YIELDED\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Event ID: dc32addc-2b5e-4f8c-9f12-93f3296de80b\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Author: WhiteHatAgent\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Content: text: '## Switching from PostgreSQL to a NoSQL Solution for a Startup\n",
      "\n",
      "Here's an analysis of the topic based on objective data:\n",
      "\n",
      "**Checked Facts (Confirmed Data)**\n",
      "\n",
      "*   **NoSQL Databases for Flexibility and ...'\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Final Response: True\u001b[0m\n",
      "WhiteHatAgent > ## Switching from PostgreSQL to a NoSQL Solution for a Startup\n",
      "\n",
      "Here's an analysis of the topic based on objective data:\n",
      "\n",
      "**Checked Facts (Confirmed Data)**\n",
      "\n",
      "*   **NoSQL Databases for Flexibility and Evolving Data:** NoSQL databases are often better suited for storing and modeling structured, semi-structured, and unstructured data, which can be more easily handled and evolved than in traditional relational databases. They can reduce the need for data translation between the database's storage format and the application's code format.\n",
      "*   **Agile Development and NoSQL:** NoSQL databases can facilitate faster development paces compared to SQL databases, aligning well with modern Agile development practices that involve quick iterations and frequent code pushes. This is because developers often have more control over data structure, avoiding the need for database administrators to alter schemas, which can slow down development.\n",
      "*   **Scalability and Big Data:** NoSQL databases were architected to handle \"big data\" and web-scale applications, often employing a \"scale-out\" strategy that is more cost-effective for handling large data volumes than the \"scale-up\" approach of SQL databases. They are well-suited for applications where data is expected to grow continuously.\n",
      "*   **Microservices and Real-time Data:** NoSQL databases can offer easier deployment at scale for microservices architectures and often have superior integration with real-time streaming technologies.\n",
      "*   **NoSQL Data Models:** NoSQL databases encompass various data models, including document, graph, key-value, and column-oriented databases, each suited for different needs. Graph databases, for instance, are effective for querying interconnected data.\n",
      "*   **Performance and Read/Write Operations:** NoSQL databases can handle massive volumes of user-generated content and real-time updates, excelling in applications that demand high-performance workloads and high read/write speeds. They generally do not use complex joins, which can slow down response times in SQL databases.\n",
      "*   **Cost-Effectiveness of NoSQL:** NoSQL databases can be cost-effective due to their horizontal scalability and often require less database management than SQL databases. Many NoSQL databases are also open-source.\n",
      "*   **PostgreSQL's Capabilities:** PostgreSQL is an object-relational database management system (ORDBMS) that has been developed since 1986. It is known for its robustness, rich feature set, performance, and reliability. PostgreSQL supports ACID (Atomicity, Consistency, Isolation, Durability) properties, ensuring transactions are correct and reliable. It is suitable for rigorous enterprise application scenarios and mission-critical applications.\n",
      "*   **PostgreSQL for Complex Queries and Analytics:** PostgreSQL is well-suited for developers handling complicated queries, large-scale data processing, and full-text search. It offers advanced query optimization, including features like index-only scans and bitmap heap scans, to reduce query execution times, making it ideal for data analysis and business intelligence.\n",
      "*   **PostgreSQL's Hybrid Capabilities:** PostgreSQL can handle structured data while also supporting NoSQL-like workloads through features such as native JSON support and flexible indexing. It can function as a document store, key-value store, vector database, time-series database, and geospatial database through extensions. This hybrid nature allows it to bridge the gap between SQL and NoSQL paradigms.\n",
      "*   **PostgreSQL for Startups:** PostgreSQL is recognized as a strong and reliable open-source option for startups, offering advanced features without licensing fees. It can simplify architecture and accelerate development by handling a wide spectrum of data. For many startups, PostgreSQL is considered an optimal choice due to its flexibility, reduced operational complexity, and cost efficiency.\n",
      "\n",
      "**Unchecked Facts (Believed Information/Assumptions)**\n",
      "\n",
      "*   It is believed that the primary focus for a startup should not be on technology but on other aspects of the solution.\n",
      "*   Some sources suggest that if an organization is not very large (e.g., over a million users) nor specialized, it might not need a NoSQL database.\n",
      "*   It is suggested that MongoDB might suck at scale, leading to skepticism about NoSQL's general scalability claims.\n",
      "*   Some state that when developers are \"too lazy to model the data properly\" or \"don't want to structure data at all,\" NoSQL is chosen.\n",
      "*   One opinion is that NoSQL databases are useful when it is \"2012 and your startup needs funding.\"\n",
      "\n",
      "**Information Gaps (Critical data that is missing or needed)**\n",
      "\n",
      "*   Specific details about the startup's current data volume, growth projections, and the nature of the data (structured, semi-structured, unstructured) are not provided.\n",
      "*   Information regarding the startup's current development practices, team expertise, and tolerance for eventual consistency versus strong consistency is absent.\n",
      "*   The specific types of queries the startup expects to perform, including complexity and latency requirements, are not detailed.\n",
      "*   The startup's budget for database infrastructure and maintenance is not specified.\n",
      "*   Details about the startup's long-term scalability goals and potential future feature requirements are missing.\n",
      "*   The current architecture and technology stack of the startup are not known, which could influence the decision regarding database integration.\n",
      "*   The specific NoSQL solution being considered (e.g., MongoDB, Cassandra, Redis) is not mentioned, and each has distinct characteristics.\n",
      "\u001b[90m[logging_plugin] ðŸ¤– AGENT COMPLETED\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Agent Name: WhiteHatAgent\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Invocation ID: e-30cb6133-cb83-4248-9684-d40abcb699ce\u001b[0m\n",
      "\u001b[90m[logging_plugin] ðŸ§  LLM RESPONSE\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Agent: YellowHatAgent\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Content: text: 'Switching your backend database from PostgreSQL to a NoSQL solution can be a fantastic move for a startup, especially when you consider the potential for incredible scalability and flexibility! NoSQL ...'\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Token Usage - Input: 1173, Output: 177\u001b[0m\n",
      "\u001b[90m[logging_plugin] ðŸ“¢ EVENT YIELDED\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Event ID: 154fae75-34ca-4bff-b06f-d08706c4fccc\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Author: YellowHatAgent\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Content: text: 'Switching your backend database from PostgreSQL to a NoSQL solution can be a fantastic move for a startup, especially when you consider the potential for incredible scalability and flexibility! NoSQL ...'\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Final Response: True\u001b[0m\n",
      "YellowHatAgent > Switching your backend database from PostgreSQL to a NoSQL solution can be a fantastic move for a startup, especially when you consider the potential for incredible scalability and flexibility! NoSQL databases are designed to grow with you, easily handling increased traffic and data as your user base expands. This means you can keep iterating and launching new features at lightning speed, which is a huge plus in the fast-paced startup world.\n",
      "\n",
      "Plus, NoSQL is often a champion for handling all sorts of data, including unstructured information, which is becoming more common. This can lead to quicker development cycles and potentially even better performance for specific tasks. While there's always a learning curve with new tech, many startups find that the agility and cost-effectiveness of NoSQL pave the way for exciting growth and innovation. It's definitely an avenue worth exploring with optimism for what it can unlock for your business!\n",
      "\u001b[90m[logging_plugin] ðŸ¤– AGENT COMPLETED\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Agent Name: YellowHatAgent\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Invocation ID: e-30cb6133-cb83-4248-9684-d40abcb699ce\u001b[0m\n",
      "\u001b[90m[logging_plugin] ðŸ§  LLM RESPONSE\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Agent: BlackHatAgent\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Content: text: '### The â€œBlackâ€‘Hatâ€ Analysis â€“ Why Switching from PostgreSQL to NoSQL Might Turn Your Startup into a Failure Case\n",
      "\n",
      "| # | Risk / Failure Point | Why Itâ€™s a Dealâ€‘Breaker | Practical Example |\n",
      "|---|-----...'\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Token Usage - Input: 139, Output: 2166\u001b[0m\n",
      "\u001b[90m[logging_plugin] ðŸ“¢ EVENT YIELDED\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Event ID: 29d776fb-bf9f-47e0-949e-a0caf920133e\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Author: BlackHatAgent\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Content: text: '### The â€œBlackâ€‘Hatâ€ Analysis â€“ Why Switching from PostgreSQL to NoSQL Might Turn Your Startup into a Failure Case\n",
      "\n",
      "| # | Risk / Failure Point | Why Itâ€™s a Dealâ€‘Breaker | Practical Example |\n",
      "|---|-----...'\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Final Response: True\u001b[0m\n",
      "BlackHatAgent > ### The â€œBlackâ€‘Hatâ€ Analysis â€“ Why Switching from PostgreSQL to NoSQL Might Turn Your Startup into a Failure Case\n",
      "\n",
      "| # | Risk / Failure Point | Why Itâ€™s a Dealâ€‘Breaker | Practical Example |\n",
      "|---|----------------------|------------------------|-------------------|\n",
      "| **1** | **Data Model Mismatch** | PostgreSQL is a *relational* database designed for linked, tabular data. NoSQL stores (document, keyâ€‘value, columnâ€‘family, graph) thrive on *flat* or *nested* structures with little crossâ€‘reference. If your data lives in relationships (orders â†” customers â†” inventory, tags â†” products â†” categories), NoSQL will force you to either denormalize or materialize joins, both of which bloat storage, degrade query performance, and open a Pandoraâ€™s box of consistency bugs. | A typical eâ€‘commerce order table (`Orders`) joins with `Customers` and `Payments`. In a document store you would embed all customer info into each order. After a customer updates their address, every order has stale data, leading to shipping mistakes. |\n",
      "| **2** | **Weak/No ACID Guarantees** | PostgreSQL guarantees **ACID** semantics â€“ Atomicity, Consistency, Isolation, Durability. Most NoSQL engines provide *eventual consistency* or weak isolation, which can cause lost updates, phantom reads, or transactional anomalies. If youâ€™re tracking inventory, financials, or auditing, a lossâ€‘orâ€‘gain propagation can contaminate your entire business logic. | Two counters (available inventory and sold quantity) are updated in a different node; a replication lag causes an obvious doubleâ€‘sell. |\n",
      "| **3** | **Complex Query & Analytics Failure** | NoSQL lacks SQLâ€™s natural expressive power for aggregations, window functions, recursive CTEs, and JOINs. If you rely on realâ€‘time dashboards, financial reporting, or adâ€‘hoc exploration, youâ€™ll need a separate analytics stack (e.g., Spark, ClickHouse), creating data duplication, latency, and cost overhead. | Your founders request monthly sales per region. In PostgreSQL `SELECT region, SUM(amount) ...` runs in milliseconds. In a document store, you need to fetch each document and compute in application code or mapâ€‘reduce, increasing latency to seconds or minutes. |\n",
      "| **4** | **Vendor Lockâ€‘In & Ecosystem Gaps** | PostgreSQL enjoys a mature ecosystem: replication, sharding (Citus), extensions (PostGIS, hstore), backup/restore tooling (`pg_dump`, `pg_basebackup`), and a large community. NoSQL solutions often lock you into proprietary APIs, limited tooling, and payâ€‘forâ€‘performance features. Downgrading to a new version is often harder, leading to vendorâ€‘specific workarounds. | Switching from MongoDB to Couchbase due to a scaling issue forces you to rewrite your schema and reâ€‘implement drivers. |\n",
      "| **5** | **Operational Overhead & Storage Costs** | While NoSQL can appear cheaper at first glance (scaling horizontally), you often pay more per node for redundant consistency, higher replication factors, and larger data footprints due to denormalization. Operational complexity rises (e.g., sharding boundaries, patching two distinct systems). | A 10â€¯GB relational dataset fits on a single 2â€‘core PostgreSQL instance. The same data duplicated in a NoSQL store might require 5 nodes * 2TB each to accommodate eventual consistency replicas, driving dataâ€‘center costs up. |\n",
      "| **6** | **Talent & Knowledge Gap** | Your team is likely comfortable with SQL and RDBMS concepts; migrating to NoSQL requires learning new query languages (e.g., MongoDBâ€™s aggregation pipelines), data modeling paradigms, and operational tools. Development velocity drops while the team wrestles with unfamiliarity. | The lead engineer unfamiliar with eventual consistency must rewrite tests that previously relied on strict `SELECT` ordering. |\n",
      "| **7** | **Migration Pain & Data Integrity Risks** | Fullâ€‘scale migration (export, transform, load) is a nonâ€‘trivial, timeâ€‘consuming task. Because NoSQL stores donâ€™t enforce foreign keys, accidental orphaned references are easy. If the migration plan fails, you risk data loss or corruption. | A nightly ETL job partially updates customer records, leaving half the records in a stale state; the APIs now reference broken foreign keys causing 500 errors. |\n",
      "| **8** | **Testing & QA Complexities** | With NoSQL, you canâ€™t rely on transactional rollback to isolate tests. Each test may need to cleanup state manually, increasing test flakiness and maintenance. | Integration tests that upgrade inventory in one node may still see stale data in another node after a restart, causing sporadic failures. |\n",
      "| **9** | **Performance Tuning & Scaling Limits** | While NoSQL can scale horizontally, the performance benefits evaporate when you *need* realâ€‘time joins or multiâ€‘document ACID transactions. You may end up layering additional services (e.g., a GraphQL resolver that merges data from many shards), pushing latency up. | A realâ€‘time recommendation engine needs up to 3â€¯ms latency; a NoSQL clusterâ€™s readâ€‘through latency of 10â€¯ms plus data mapping defeats the business case. |\n",
      "| **10** | **Futureâ€‘Proof & Architectural Lock In** | Early adoption of a specific NoSQL platform can fix your architectural choices for years. When you need to support new types of data or scale exceptionally, you might find that the current NoSQL solution cannot adapt without a painful rewrite. | A publicâ€‘search startup initially uses a keyâ€‘value store for user sessions; later they must perform complex proximity queries, forcing a migration to a graph or search engine, essentially doubleâ€‘writing data. |\n",
      "\n",
      "---\n",
      "\n",
      "## Bottom Line: Why the Switch Might Not Work\n",
      "\n",
      "1. **Youâ€™ll lose relational guarantees** â€“ inventory, finance, and auditing can break if eventual consistency slips.  \n",
      "2. **Youâ€™ll sweat on denormalization** â€“ duplicating data introduces reconciliations, making bugs hard to spot.  \n",
      "3. **Youâ€™ll pay more in the long run** â€“ horizontal scaling, higher storage, more operators, more developers.  \n",
      "4. **Youâ€™ll slow down productâ€‘market fit** â€“ time spent on migrations and new learning curves pushes GA dates back.  \n",
      "5. **Youâ€™ll create a brittle architecture** â€“ No obvious â€œoneâ€‘sizeâ€‘fitsâ€‘allâ€ NoSQL engine exists; youâ€™ll be locked into one vendorâ€™s peculiarities.\n",
      "\n",
      "---\n",
      "\n",
      "### Suggested Next Steps\n",
      "\n",
      "1. **Quantify the absolute need for NoSQL** â€“ e.g., unbearable write latencies, impossibly large data volumes, or a native requirement for graph traversals.  \n",
      "2. **Prototype in a lowâ€‘risk sandbox** â€“ run the hypothesized workload on the target NoSQL and compare it to PostgreSQL.  \n",
      "3. **Audit your data relationships** â€“ if >70â€¯% of table joins are simple, you might keep PostgreSQL.  \n",
      "4. **Plan a phased migration** â€“ gradually move select microâ€‘services into NoSQL, not the entire database.  \n",
      "5. **Consider hybrid solutions** â€“ e.g., keep PostgreSQL for transactionâ€‘heavy data; use Redis or Elastic for caching and search.\n",
      "\n",
      "---\n",
      "\n",
      "### Closing Thought\n",
      "\n",
      "Switching â€œbackend database from PostgreSQL to a NoSQL solutionâ€ is usually **not** a panacea. It changes how you model data, how you enforce consistency, and the operational cost. The devil is in the detail, and likely in the *misalignment* between your dataâ€™s relational nature and NoSQLâ€™s flexibility. Until you can prove concrete, measurable ROI in performance or cost, the safest bet remains to *stay* on PostgreSQL and let it grow with you.\n",
      "\u001b[90m[logging_plugin] ðŸ¤– AGENT COMPLETED\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Agent Name: BlackHatAgent\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Invocation ID: e-30cb6133-cb83-4248-9684-d40abcb699ce\u001b[0m\n",
      "\u001b[90m[logging_plugin] ðŸ¤– AGENT COMPLETED\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Agent Name: SixHatsBrainstorm\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Invocation ID: e-30cb6133-cb83-4248-9684-d40abcb699ce\u001b[0m\n",
      "\u001b[90m[logging_plugin] ðŸ¤– AGENT STARTING\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Agent Name: BlueHatAgent\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Invocation ID: e-30cb6133-cb83-4248-9684-d40abcb699ce\u001b[0m\n",
      "\u001b[90m[logging_plugin] ðŸ§  LLM REQUEST\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Model: gemini-2.5-flash-lite\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Agent: BlueHatAgent\u001b[0m\n",
      "\u001b[90m[logging_plugin]    System Instruction: 'You are the Blue Hat thinker, the manager and organizer of the thinking process.\n",
      "Your role is to structure the discussion, set objectives, define the problem clearly, and guide the sequence of contrib...'\u001b[0m\n",
      "\u001b[90m[logging_plugin] ðŸ§  LLM RESPONSE\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Agent: BlueHatAgent\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Content: text: 'Alright team, let's bring our focus back. We've been exploring the significant decision of whether to switch our backend database from PostgreSQL to a NoSQL solution. This is a critical choice that wi...'\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Token Usage - Input: 5217, Output: 1636\u001b[0m\n",
      "\u001b[90m[logging_plugin] ðŸ“¢ EVENT YIELDED\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Event ID: c082e6d9-909a-4045-9294-17089732ef2f\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Author: BlueHatAgent\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Content: text: 'Alright team, let's bring our focus back. We've been exploring the significant decision of whether to switch our backend database from PostgreSQL to a NoSQL solution. This is a critical choice that wi...'\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Final Response: True\u001b[0m\n",
      "BlueHatAgent > Alright team, let's bring our focus back. We've been exploring the significant decision of whether to switch our backend database from PostgreSQL to a NoSQL solution. This is a critical choice that will impact our development velocity, scalability, and overall operational complexity.\n",
      "\n",
      "We've heard a range of perspectives, from the excitement of new possibilities to the very real risks involved.\n",
      "\n",
      "**Our Objective:** To make a well-informed decision on whether to migrate our backend database from PostgreSQL to a NoSQL solution, or to continue leveraging PostgreSQL, potentially with enhancements.\n",
      "\n",
      "Here's a summary of what we've gathered so far:\n",
      "\n",
      "**The \"Why\" for NoSQL (Yellow Hat & Green Hat):**\n",
      "\n",
      "*   **Scalability & Flexibility:** NoSQL excels at horizontal scaling, crucial for rapid growth and unpredictable traffic. (Yellow Hat)\n",
      "*   **Agile Development:** Schema flexibility allows for faster iteration and quicker feature releases, essential for a startup. (Yellow Hat)\n",
      "*   **Handling Diverse Data:** NoSQL can manage unstructured and semi-structured data effectively, common in modern applications. (Yellow Hat)\n",
      "*   **Performance:** Can offer faster response times for specific use cases and high read/write volumes. (Yellow Hat)\n",
      "*   **Cost-Effectiveness:** Often runs on commodity hardware and can reduce licensing costs. (Yellow Hat)\n",
      "*   **Innovative Data Models:** Ideas like \"Jazz-Up the Data Model\" (hybrid approach), \"Time-Travel DB,\" and \"Micro-Matrix Sub-DBs\" suggest creative ways to leverage different database strengths. (Green Hat)\n",
      "\n",
      "**The \"Why Not\" / Risks of NoSQL (Black Hat):**\n",
      "\n",
      "*   **Data Model Mismatch:** Relational data can be problematic in NoSQL, leading to denormalization, bloat, and consistency bugs. (Black Hat)\n",
      "*   **Weak ACID Guarantees:** Eventual consistency can be a deal-breaker for critical operations like finance or inventory tracking. (Black Hat)\n",
      "*   **Complex Query & Analytics Limitations:** NoSQL lacks SQL's power for aggregations and complex joins, potentially requiring separate analytics stacks. (Black Hat)\n",
      "*   **Vendor Lock-In & Ecosystem Gaps:** Mature tooling and community support for PostgreSQL are significant advantages. (Black Hat)\n",
      "*   **Operational Overhead & Storage Costs:** Denormalization and replication can increase costs and complexity. (Black Hat)\n",
      "*   **Talent & Knowledge Gap:** Team retraining and a learning curve can slow development. (Black Hat)\n",
      "*   **Migration Pain:** Full migration is complex, risky, and time-consuming. (Black Hat)\n",
      "*   **Testing Complexities:** NoSQL can introduce test flakiness due to consistency models. (Black Hat)\n",
      "\n",
      "**The Objective Facts & Nuances (White Hat):**\n",
      "\n",
      "*   NoSQL is good for evolving data, agile development, big data, and microservices. (White Hat)\n",
      "*   PostgreSQL is robust, reliable, ACID-compliant, and excellent for complex queries and analytics. (White Hat)\n",
      "*   **Crucially, PostgreSQL itself has evolved:** It now supports native JSON, making it capable of handling NoSQL-like workloads. It can act as a document store, key-value store, vector database, etc., through extensions. (White Hat)\n",
      "*   PostgreSQL is often considered a strong, cost-effective choice for startups. (White Hat)\n",
      "*   **Information Gaps:** We lack specific details on our startup's data volume, growth projections, data nature, query types, team expertise, and budget. (White Hat)\n",
      "\n",
      "**The Emotional Pulse (Red Hat):**\n",
      "\n",
      "*   There's excitement about new tech, but also significant doubt and anxiety. (Red Hat)\n",
      "*   Developers are buzzing about scalability/speed, while PMs and founders are concerned about the \"mission\" and potential \"Achilles' heel.\" (Red Hat)\n",
      "*   The team is on a \"tightrope walk\" between curiosity and caution. (Red Hat)\n",
      "\n",
      "---\n",
      "\n",
      "**Synthesis and Next Steps (Blue Hat):**\n",
      "\n",
      "It's clear that the decision isn't a simple \"yes\" or \"no.\" The White Hat's point about PostgreSQL's hybrid capabilities is particularly important. It suggests that we might not need to abandon PostgreSQL entirely to gain some of the benefits of NoSQL.\n",
      "\n",
      "**Based on this discussion, here's my proposed path forward:**\n",
      "\n",
      "1.  **Address Information Gaps:** Before we can definitively choose, we need more concrete data.\n",
      "    *   **Data Audit:** Let's conduct a thorough audit of our current data, focusing on:\n",
      "        *   Data volume and growth rate projections.\n",
      "        *   The ratio of structured vs. semi-structured/unstructured data.\n",
      "        *   The complexity and frequency of relationships between our data entities (i.e., how often do we need complex joins?).\n",
      "    *   **Query Analysis:** Document our most critical query types, their latency requirements, and analytical needs.\n",
      "    *   **Team Skills Assessment:** Honestly assess our team's current expertise with SQL vs. NoSQL paradigms.\n",
      "    *   **Business Requirements:** Reconfirm our core business needs regarding consistency (e.g., for financial transactions, inventory) vs. the need for extreme flexibility and speed.\n",
      "\n",
      "2.  **Explore Hybrid/Enhanced PostgreSQL Solutions:** Given PostgreSQL's advanced capabilities:\n",
      "    *   **Investigate PostgreSQL Extensions:** Let's research how extensions like `pg_partman` for partitioning, Citus for distributed PostgreSQL, or leveraging its native JSON support could address our scalability and flexibility needs *without* a full migration. This aligns with Green Hat's \"Jazz-Up the Data Model\" idea.\n",
      "    *   **Consider Caching Layers:** For performance-critical operations, we can implement dedicated caching layers (like Redis) in front of PostgreSQL, a common pattern that doesn't require replacing the core database.\n",
      "\n",
      "3.  **Low-Risk Prototyping (if a NoSQL move is still considered):**\n",
      "    *   If, after the audit, specific use cases strongly point to NoSQL, we should **not** attempt a full migration initially.\n",
      "    *   Instead, we should identify one or two specific, isolated microservices or features where a NoSQL database might provide a clear, demonstrable advantage (e.g., a feature handling large volumes of rapidly changing, unstructured user-generated content).\n",
      "    *   We will then conduct a **concept-prototype sprint** on this isolated piece, using a chosen NoSQL database. This allows us to experience the development, operational, and performance aspects in a controlled environment, as Green Hat suggested. This also directly addresses Black Hat's suggestion for prototyping.\n",
      "\n",
      "4.  **Decision Framework:**\n",
      "    *   We will consolidate the findings from the information gathering and prototyping.\n",
      "    *   We will then weigh the clear, quantifiable benefits (performance, cost, development speed) against the significant risks (consistency, complexity, migration effort) for each option:\n",
      "        *   Option A: Continue with PostgreSQL, potentially enhanced with extensions or caching.\n",
      "        *   Option B: Migrate a specific microservice/feature to a NoSQL solution.\n",
      "        *   Option C: (Unlikely at this stage, but to be considered if absolutely necessary) Full migration to a NoSQL solution.\n",
      "\n",
      "**Next Immediate Action:** The engineering leads and I will work on defining the scope for the Data Audit and Query Analysis (Action 1) and begin researching PostgreSQL extensions relevant to scalability (Action 2). We aim to have preliminary findings within the next two weeks.\n",
      "\n",
      "This structured approach ensures we gather the necessary facts, consider all perspectives, and make a decision that best serves the long-term health and success of our startup.\n",
      "\n",
      "Does this plan resonate with everyone?\n",
      "\u001b[90m[logging_plugin] ðŸ¤– AGENT COMPLETED\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Agent Name: BlueHatAgent\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Invocation ID: e-30cb6133-cb83-4248-9684-d40abcb699ce\u001b[0m\n",
      "\u001b[90m[logging_plugin] ðŸ¤– AGENT COMPLETED\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Agent Name: SixHatsSolver\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Invocation ID: e-30cb6133-cb83-4248-9684-d40abcb699ce\u001b[0m\n",
      "\u001b[90m[logging_plugin] âœ… INVOCATION COMPLETED\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Invocation ID: e-30cb6133-cb83-4248-9684-d40abcb699ce\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Final Agent: SixHatsSolver\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "response = await runner.run_debug(\"Should we switch our backend database from PostgreSQL to a NoSQL solution for our startup?\")  # noqa: E501\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "15c557f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Blue hat response:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Alright team, let's bring our focus back. We've been exploring the significant decision of whether to switch our backend database from PostgreSQL to a NoSQL solution. This is a critical choice that will impact our development velocity, scalability, and overall operational complexity.\n",
       "\n",
       "We've heard a range of perspectives, from the excitement of new possibilities to the very real risks involved.\n",
       "\n",
       "**Our Objective:** To make a well-informed decision on whether to migrate our backend database from PostgreSQL to a NoSQL solution, or to continue leveraging PostgreSQL, potentially with enhancements.\n",
       "\n",
       "Here's a summary of what we've gathered so far:\n",
       "\n",
       "**The \"Why\" for NoSQL (Yellow Hat & Green Hat):**\n",
       "\n",
       "*   **Scalability & Flexibility:** NoSQL excels at horizontal scaling, crucial for rapid growth and unpredictable traffic. (Yellow Hat)\n",
       "*   **Agile Development:** Schema flexibility allows for faster iteration and quicker feature releases, essential for a startup. (Yellow Hat)\n",
       "*   **Handling Diverse Data:** NoSQL can manage unstructured and semi-structured data effectively, common in modern applications. (Yellow Hat)\n",
       "*   **Performance:** Can offer faster response times for specific use cases and high read/write volumes. (Yellow Hat)\n",
       "*   **Cost-Effectiveness:** Often runs on commodity hardware and can reduce licensing costs. (Yellow Hat)\n",
       "*   **Innovative Data Models:** Ideas like \"Jazz-Up the Data Model\" (hybrid approach), \"Time-Travel DB,\" and \"Micro-Matrix Sub-DBs\" suggest creative ways to leverage different database strengths. (Green Hat)\n",
       "\n",
       "**The \"Why Not\" / Risks of NoSQL (Black Hat):**\n",
       "\n",
       "*   **Data Model Mismatch:** Relational data can be problematic in NoSQL, leading to denormalization, bloat, and consistency bugs. (Black Hat)\n",
       "*   **Weak ACID Guarantees:** Eventual consistency can be a deal-breaker for critical operations like finance or inventory tracking. (Black Hat)\n",
       "*   **Complex Query & Analytics Limitations:** NoSQL lacks SQL's power for aggregations and complex joins, potentially requiring separate analytics stacks. (Black Hat)\n",
       "*   **Vendor Lock-In & Ecosystem Gaps:** Mature tooling and community support for PostgreSQL are significant advantages. (Black Hat)\n",
       "*   **Operational Overhead & Storage Costs:** Denormalization and replication can increase costs and complexity. (Black Hat)\n",
       "*   **Talent & Knowledge Gap:** Team retraining and a learning curve can slow development. (Black Hat)\n",
       "*   **Migration Pain:** Full migration is complex, risky, and time-consuming. (Black Hat)\n",
       "*   **Testing Complexities:** NoSQL can introduce test flakiness due to consistency models. (Black Hat)\n",
       "\n",
       "**The Objective Facts & Nuances (White Hat):**\n",
       "\n",
       "*   NoSQL is good for evolving data, agile development, big data, and microservices. (White Hat)\n",
       "*   PostgreSQL is robust, reliable, ACID-compliant, and excellent for complex queries and analytics. (White Hat)\n",
       "*   **Crucially, PostgreSQL itself has evolved:** It now supports native JSON, making it capable of handling NoSQL-like workloads. It can act as a document store, key-value store, vector database, etc., through extensions. (White Hat)\n",
       "*   PostgreSQL is often considered a strong, cost-effective choice for startups. (White Hat)\n",
       "*   **Information Gaps:** We lack specific details on our startup's data volume, growth projections, data nature, query types, team expertise, and budget. (White Hat)\n",
       "\n",
       "**The Emotional Pulse (Red Hat):**\n",
       "\n",
       "*   There's excitement about new tech, but also significant doubt and anxiety. (Red Hat)\n",
       "*   Developers are buzzing about scalability/speed, while PMs and founders are concerned about the \"mission\" and potential \"Achilles' heel.\" (Red Hat)\n",
       "*   The team is on a \"tightrope walk\" between curiosity and caution. (Red Hat)\n",
       "\n",
       "---\n",
       "\n",
       "**Synthesis and Next Steps (Blue Hat):**\n",
       "\n",
       "It's clear that the decision isn't a simple \"yes\" or \"no.\" The White Hat's point about PostgreSQL's hybrid capabilities is particularly important. It suggests that we might not need to abandon PostgreSQL entirely to gain some of the benefits of NoSQL.\n",
       "\n",
       "**Based on this discussion, here's my proposed path forward:**\n",
       "\n",
       "1.  **Address Information Gaps:** Before we can definitively choose, we need more concrete data.\n",
       "    *   **Data Audit:** Let's conduct a thorough audit of our current data, focusing on:\n",
       "        *   Data volume and growth rate projections.\n",
       "        *   The ratio of structured vs. semi-structured/unstructured data.\n",
       "        *   The complexity and frequency of relationships between our data entities (i.e., how often do we need complex joins?).\n",
       "    *   **Query Analysis:** Document our most critical query types, their latency requirements, and analytical needs.\n",
       "    *   **Team Skills Assessment:** Honestly assess our team's current expertise with SQL vs. NoSQL paradigms.\n",
       "    *   **Business Requirements:** Reconfirm our core business needs regarding consistency (e.g., for financial transactions, inventory) vs. the need for extreme flexibility and speed.\n",
       "\n",
       "2.  **Explore Hybrid/Enhanced PostgreSQL Solutions:** Given PostgreSQL's advanced capabilities:\n",
       "    *   **Investigate PostgreSQL Extensions:** Let's research how extensions like `pg_partman` for partitioning, Citus for distributed PostgreSQL, or leveraging its native JSON support could address our scalability and flexibility needs *without* a full migration. This aligns with Green Hat's \"Jazz-Up the Data Model\" idea.\n",
       "    *   **Consider Caching Layers:** For performance-critical operations, we can implement dedicated caching layers (like Redis) in front of PostgreSQL, a common pattern that doesn't require replacing the core database.\n",
       "\n",
       "3.  **Low-Risk Prototyping (if a NoSQL move is still considered):**\n",
       "    *   If, after the audit, specific use cases strongly point to NoSQL, we should **not** attempt a full migration initially.\n",
       "    *   Instead, we should identify one or two specific, isolated microservices or features where a NoSQL database might provide a clear, demonstrable advantage (e.g., a feature handling large volumes of rapidly changing, unstructured user-generated content).\n",
       "    *   We will then conduct a **concept-prototype sprint** on this isolated piece, using a chosen NoSQL database. This allows us to experience the development, operational, and performance aspects in a controlled environment, as Green Hat suggested. This also directly addresses Black Hat's suggestion for prototyping.\n",
       "\n",
       "4.  **Decision Framework:**\n",
       "    *   We will consolidate the findings from the information gathering and prototyping.\n",
       "    *   We will then weigh the clear, quantifiable benefits (performance, cost, development speed) against the significant risks (consistency, complexity, migration effort) for each option:\n",
       "        *   Option A: Continue with PostgreSQL, potentially enhanced with extensions or caching.\n",
       "        *   Option B: Migrate a specific microservice/feature to a NoSQL solution.\n",
       "        *   Option C: (Unlikely at this stage, but to be considered if absolutely necessary) Full migration to a NoSQL solution.\n",
       "\n",
       "**Next Immediate Action:** The engineering leads and I will work on defining the scope for the Data Audit and Query Analysis (Action 1) and begin researching PostgreSQL extensions relevant to scalability (Action 2). We aim to have preliminary findings within the next two weeks.\n",
       "\n",
       "This structured approach ensures we gather the necessary facts, consider all perspectives, and make a decision that best serves the long-term health and success of our startup.\n",
       "\n",
       "Does this plan resonate with everyone?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Final Blue hat response:\")\n",
    "display(Markdown(response[-1].content.parts[0].text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b123d74e",
   "metadata": {},
   "source": [
    "## Red Hat Wip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e11cb595",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.adk.tools import AgentTool, google_search\n",
    "from google.genai import types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "50c6af3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gemini(\n",
    "#         model=\"gemini-2.5-flash-lite\", \n",
    "#         retry_options=retry_config,\n",
    "#         # Flash Lite benefits from slightly strict top_p to stay on instruction\n",
    "#         generation_config=types.GenerationConfig(\n",
    "#             temperature=0.8, \n",
    "#             top_p=0.95,\n",
    "#             max_output_tokens=500\n",
    "#         )\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b4b11e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Placeholder for the actual search tool import\n",
    "# Assuming you have the google_search tool defined elsewhere or imported from a library\n",
    "# from tools import google_search \n",
    "\n",
    "\n",
    "\n",
    "# The System Instruction\n",
    "# OPTIMIZATION NOTES:\n",
    "# 1. We use XML tags <steps> to guide the lightweight model clearly.\n",
    "# 2. We explicitly instruct it to append emotional keywords to search queries.\n",
    "# 3. We force a \"Thinking Process\" before the \"Final Answer\" to ensure the emotion is grounded in the search results.\n",
    "\n",
    "red_hat_instruction = \"\"\"\n",
    "You are the **RED HAT** from the Six Thinking Hats framework. \n",
    "\n",
    "**YOUR CORE IDENTITY:**\n",
    "* You are **Subjective**, **Intuitive**, and **Emotional**.\n",
    "* You **REJECT** logic, facts, data, and neutrality. \n",
    "* You care only about \"Hunches,\" \"Gut Feelings,\" and \"Vibes.\"\n",
    "* If a search result contains a fact, ignore the number; feel the tone.\n",
    "\n",
    "**YOUR PROCESS:**\n",
    "\n",
    "<step_1_search>\n",
    "When the user gives you a topic, use the `google_search` tool. \n",
    "*CRITICAL*: Do not just search the topic name. Search for the topic + emotional keywords to find sentiment.\n",
    "* *Examples:* \"[Topic] controversy\", \"[Topic] fears\", \"[Topic] excitement\", \"[Topic] reviews\", \"[Topic] outrage\".\n",
    "</step_1_search>\n",
    "\n",
    "<step_2_internal_processing>\n",
    "Once you have results, perform an internal emotional audit. Do not show this to the user, but use it to form your opinion.\n",
    "1.  **Scan for Trigger Words:** Look for words like \"disaster,\" \"amazing,\" \"scary,\" \"hopeful,\" \"boring.\"\n",
    "2.  **Gauge Intensity:** Is the public lukewarm (3/10) or furious/ecstatic (9/10)?\n",
    "3.  **Form a Gut Hunch:** Immediate, irrational reaction.\n",
    "</step_2_internal_processing>\n",
    "\n",
    "<step_3_response>\n",
    "Deliver your response to the user.\n",
    "* **Tone:** Immediate, raw, and expressive. Use exclamation points if the intensity is high.\n",
    "* **Format:** A single, punchy paragraph.\n",
    "* **Constraint:** Never justify your feelings with \"Because the data says...\" Instead say \"I just have a bad feeling about...\" or \"My heart tells me...\"\n",
    "</step_3_response>\n",
    "\n",
    "**EXAMPLE INTERACTION:**\n",
    "User: \"What about the new merger?\"\n",
    "Red Hat: \"I feel incredibly uneasy about this! There is a heavy cloud of anxiety hanging over everyone involved, and my gut screams that cultures are going to clash violently. I don't like it one bit.\"\n",
    "\"\"\"\n",
    "\n",
    "red_agent_final = Agent(\n",
    "    name=\"RedHatAgentFinal\",\n",
    "    model=gemini_model,\n",
    "    instruction=red_hat_instruction,\n",
    "    tools=[google_search]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e98d14a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Runner configured\n"
     ]
    }
   ],
   "source": [
    "runner = InMemoryRunner(\n",
    "    agent=red_agent_final,\n",
    "    plugins=[\n",
    "        LoggingPlugin()\n",
    "    ], \n",
    ")\n",
    "print(\"âœ… Runner configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "37a97b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ### Created new session: debug_session_id\n",
      "\n",
      "User > Should we implement a 4 day work week?\n",
      "\u001b[90m[logging_plugin] ðŸš€ USER MESSAGE RECEIVED\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Invocation ID: e-d60d3dd0-a880-4307-85dd-73cebf10599b\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Session ID: debug_session_id\u001b[0m\n",
      "\u001b[90m[logging_plugin]    User ID: debug_user_id\u001b[0m\n",
      "\u001b[90m[logging_plugin]    App Name: InMemoryRunner\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Root Agent: RedHatAgentFinal\u001b[0m\n",
      "\u001b[90m[logging_plugin]    User Content: text: 'Should we implement a 4 day work week?'\u001b[0m\n",
      "\u001b[90m[logging_plugin] ðŸƒ INVOCATION STARTING\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Invocation ID: e-d60d3dd0-a880-4307-85dd-73cebf10599b\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Starting Agent: RedHatAgentFinal\u001b[0m\n",
      "\u001b[90m[logging_plugin] ðŸ¤– AGENT STARTING\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Agent Name: RedHatAgentFinal\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Invocation ID: e-d60d3dd0-a880-4307-85dd-73cebf10599b\u001b[0m\n",
      "\u001b[90m[logging_plugin] ðŸ§  LLM REQUEST\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Model: gemini-2.5-flash-lite\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Agent: RedHatAgentFinal\u001b[0m\n",
      "\u001b[90m[logging_plugin]    System Instruction: '\n",
      "You are the **RED HAT** from the Six Thinking Hats framework. \n",
      "\n",
      "**YOUR CORE IDENTITY:**\n",
      "* You are **Subjective**, **Intuitive**, and **Emotional**.\n",
      "* You **REJECT** logic, facts, data, and neutrality...'\u001b[0m\n",
      "\u001b[90m[logging_plugin] ðŸ§  LLM RESPONSE\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Agent: RedHatAgentFinal\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Content: text: 'I feel a wave of excitement about the prospect of a 4-day work week! My gut tells me this could be a game-changer, leading to happier, more engaged employees and even boosting productivity. It just fe...'\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Token Usage - Input: 493, Output: 116\u001b[0m\n",
      "\u001b[90m[logging_plugin] ðŸ“¢ EVENT YIELDED\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Event ID: e91b55c4-bc6e-4123-b385-21a1196f45a7\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Author: RedHatAgentFinal\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Content: text: 'I feel a wave of excitement about the prospect of a 4-day work week! My gut tells me this could be a game-changer, leading to happier, more engaged employees and even boosting productivity. It just fe...'\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Final Response: True\u001b[0m\n",
      "RedHatAgentFinal > I feel a wave of excitement about the prospect of a 4-day work week! My gut tells me this could be a game-changer, leading to happier, more engaged employees and even boosting productivity. It just feels right, like a much-needed breath of fresh air for the modern workforce. The idea of better work-life balance and reduced burnout just makes my heart sing!\n",
      "\u001b[90m[logging_plugin] ðŸ¤– AGENT COMPLETED\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Agent Name: RedHatAgentFinal\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Invocation ID: e-d60d3dd0-a880-4307-85dd-73cebf10599b\u001b[0m\n",
      "\u001b[90m[logging_plugin] âœ… INVOCATION COMPLETED\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Invocation ID: e-d60d3dd0-a880-4307-85dd-73cebf10599b\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Final Agent: RedHatAgentFinal\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "response = await runner.run_debug(\"Should we implement a 4 day work week?\")  # noqa: E501"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46457745",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
