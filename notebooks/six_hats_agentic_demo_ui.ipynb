{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a7786f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from google.genai import types\n",
    "from google.adk.agents import Agent, ParallelAgent, SequentialAgent\n",
    "from google.adk.models.google_llm import Gemini\n",
    "from pathlib import Path\n",
    "from agents_intensive_capstone.agents import blue_hat_agent, green_hat_agent, yellow_hat_agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ac8a2a",
   "metadata": {},
   "source": [
    "## Configure Retry Options¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf52c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "# 2. Access the variable\n",
    "api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "print(\"✅ Gemini API key setup complete.\")\n",
    "\n",
    "retry_config = types.HttpRetryOptions(\n",
    "    attempts=5,  # Maximum retry attempts\n",
    "    exp_base=7,  # Delay multiplier\n",
    "    initial_delay=1,\n",
    "    http_status_codes=[429, 500, 503, 504],  # Retry on these HTTP errors\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0f507b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Gemini(\n",
    "    model=\"gemini-2.5-flash-lite\",\n",
    "    retry_options=retry_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48efdf46",
   "metadata": {},
   "outputs": [],
   "source": [
    "blue_hat = blue_hat_agent.BlueHatAgent.create(\n",
    "    model=model,\n",
    "    prompt_folder=Path(\"../src/agents_intensive_capstone/prompts\"),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8ea483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GREEN HAT: Creativity & Alternatives\n",
    "green_hat = green_hat_agent.GreenHatAgent(\n",
    "    model=model,\n",
    "    prompt_folder=Path(\"../src/agents_intensive_capstone/prompts\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc4f5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YELLOW HAT: Optimism & Benefits\n",
    "yellow_hat = yellow_hat_agent.YellowHatAgent(\n",
    "    model=model,\n",
    "    prompt_folder=Path(\"../src/agents_intensive_capstone/prompts\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e78e5fa",
   "metadata": {},
   "source": [
    "## Six thinking hats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e1b18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the 5 \"Thinking\" Agents (The Team)\n",
    "# WHITE HAT: Facts & Data\n",
    "white_hat = Agent(\n",
    "    name=\"WhiteHat\",\n",
    "    model=model,\n",
    "    instruction=\"You are the White Hat. Focus ONLY on available data, facts, and information gaps. Be objective and neutral. Do not offer opinions, only verifiable facts or questions about missing data.\",\n",
    ")\n",
    "\n",
    "# RED HAT: Emotions & Intuition\n",
    "red_hat = Agent(\n",
    "    name=\"RedHat\",\n",
    "    model=model,\n",
    "    instruction=\"You are the Red Hat. Focus on intuition, hunches, and emotional reaction. How does this problem make users or the team feel? You do not need to justify your feelings with logic.\",\n",
    ")\n",
    "\n",
    "# BLACK HAT: Caution & Risk\n",
    "black_hat = Agent(\n",
    "    name=\"BlackHat\",\n",
    "    model=model,\n",
    "    instruction=\"You are the Black Hat. Play the devil's advocate. Identify specific risks, potential failure points, downsides, and why this idea might NOT work. Be critical.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21a5734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Parallel Group\n",
    "# This runs all 5 agents at the same time on the user prompt\n",
    "thinking_team = ParallelAgent(\n",
    "    name=\"SixHatsBrainstorm\",\n",
    "    sub_agents=[white_hat, red_hat, black_hat, yellow_hat, green_hat]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400c65bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Final Workflow\n",
    "# First run the team (Parallel), then run the manager (Sequential)\n",
    "solver_workflow = SequentialAgent(\n",
    "    name=\"SixHatsSolver\",\n",
    "    sub_agents=[thinking_team, blue_hat]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c6ed4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.adk.runners import InMemoryRunner\n",
    "from google.adk.plugins.logging_plugin import (\n",
    "    LoggingPlugin,\n",
    ")  # <---- 1. Import the Plugin\n",
    "from google.genai import types\n",
    "import asyncio\n",
    "\n",
    "runner = InMemoryRunner(\n",
    "    agent=solver_workflow,\n",
    "    plugins=[\n",
    "        LoggingPlugin()\n",
    "    ], \n",
    ")\n",
    "print(\"✅ Runner configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06d4248",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = await runner.run_debug(\"Should we switch our backend database from PostgreSQL to a NoSQL solution for our startup?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
